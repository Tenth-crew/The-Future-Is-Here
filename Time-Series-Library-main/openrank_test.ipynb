{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174334f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository      | Status     | Info\n",
      "--------------------------------------------------\n",
      "vue             | SUCCESS    | DTA: 95.71\n",
      "react-naive     | SUCCESS    | DTA: 62.79\n",
      "\n",
      "==================================================\n",
      "所有数据处理完成！结果已保存至: workresult/stacking/openrank_DTA/experiment_master_data.csv\n",
      "成功处理仓库数量: 2\n"
     ]
    }
   ],
   "source": [
    "# 著名仓库对比数据提取 //大型仓库数据量少，在算spearman相关系数的时候无法有差异化结果，所以暂不以其作为表格结果\n",
    "# 该文件主要是针对openrank比赛需要的代码\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ================= 配置区域 =================\n",
    "repoName = ['vue', 'react-naive']\n",
    "\n",
    "# 权重定义\n",
    "ISSUECOMMENT_WEIGHT = 0.5252\n",
    "OPENISSUE_WEIGHT = 2.2235\n",
    "OPENPR_WEIGHT = 4.0679\n",
    "PRREVIEWCOMMENT_WEIGHT = 0.7427\n",
    "MERGEPR_WEIGHT = 2.0339\n",
    "WEIGHT = np.array([ISSUECOMMENT_WEIGHT, OPENISSUE_WEIGHT, OPENPR_WEIGHT, PRREVIEWCOMMENT_WEIGHT, MERGEPR_WEIGHT])\n",
    "\n",
    "# 常量定义\n",
    "PRED_LEN = 84\n",
    "SEQ_LEN = 84  # 历史回溯长度\n",
    "WEIGHT_SUM = np.sum(WEIGHT) # 约为 9.5932\n",
    "MIN_SCORE_STD = WEIGHT_SUM * 0.5 # Sigmoid(0)=0.5, 4.7966\n",
    "MAX_SCORE_STD = WEIGHT_SUM * 1.0 # Sigmoid(inf)=1.0, 9.5932\n",
    "\n",
    "# ================= 工具函数 =================\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def calculate_lte(history_data):\n",
    "    \"\"\"\n",
    "    计算线性趋势外推 (Linear Trend Extrapolation)\n",
    "    :param history_data: shape (84, 5)\n",
    "    :return: 预测未来84步的均值\n",
    "    \"\"\"\n",
    "    n_steps, n_features = history_data.shape\n",
    "    X = np.arange(n_steps).reshape(-1, 1) # [0, 1, ..., 83]\n",
    "    X_future = np.arange(n_steps, n_steps * 2).reshape(-1, 1) # [84, ..., 167]\n",
    "    \n",
    "    predictions = []\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # 对5个特征分别拟合\n",
    "    for i in range(n_features):\n",
    "        y = history_data.iloc[:, i].values\n",
    "        model.fit(X, y)\n",
    "        pred_future = model.predict(X_future)\n",
    "        predictions.append(pred_future.mean())\n",
    "        \n",
    "    return np.mean(predictions)\n",
    "\n",
    "# ================= 主逻辑 =================\n",
    "results = []\n",
    "\n",
    "print(f\"{'Repository':<15} | {'Status':<10} | {'Info'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name in repoName:\n",
    "    # 1. 构建文件路径\n",
    "    # 注意：这里假设你的 dataset 文件夹结构为 dataset/{name}/{name}_all_roll_ewma_span28_normalize.csv\n",
    "    csv_path = f'dataset/{name}/{name}_to2017end.csv'\n",
    "    pred_path = f'results/stacking_attention_fusion_PatchTST_Dlinear_custom_{name}_ftM_sl84_ll84_pl84_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0/pred.npy'\n",
    "\n",
    "    # 2. 检查文件是否存在\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"{name:<15} | MISSING    | Pred file not found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"{name:<15} | MISSING    | CSV file not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 3. 加载数据\n",
    "        pred = np.load(pred_path)\n",
    "        # 提取第一个测试样本的预测值 (假设 pred shape 为 [Batch, 84, 5])\n",
    "        # 如果只想分析特定样本，这里索引保持为 0\n",
    "        pred_data = pred[0, :PRED_LEN, :5] \n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'date' in df.columns:\n",
    "            df = df.drop(columns=['date'])\n",
    "\n",
    "        # 4. 确定时间窗口索引\n",
    "        dataset_len = len(df)\n",
    "        num_test = int(dataset_len * 0.2)\n",
    "        \n",
    "        # 预测窗口 (Future / Ground Truth)\n",
    "        start_index = dataset_len - num_test\n",
    "        end_index = start_index + PRED_LEN\n",
    "        \n",
    "        # 历史窗口 (History / Baseline Input)\n",
    "        hist_start = start_index - SEQ_LEN\n",
    "        hist_end = start_index\n",
    "\n",
    "        # 边界检查\n",
    "        if hist_start < 0:\n",
    "            print(f\"{name:<15} | WARNING    | History window out of bounds, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # 提取序列\n",
    "        true_data = df.iloc[start_index:end_index] # 未来真实值\n",
    "        hist_data = df.iloc[hist_start:hist_end]   # 历史输入值\n",
    "\n",
    "        # ================= 计算指标 =================\n",
    "        \n",
    "        # --- A. 我们的指标 (Ours) ---\n",
    "        \n",
    "        # 1. DTA Standard (标准版)\n",
    "        # 逻辑: Mean -> Sigmoid -> Weighted Sum -> Scale\n",
    "        mean_values = np.mean(pred_data, axis=0)\n",
    "        sigmoid_values = sigmoid(mean_values)\n",
    "        weighted_sum_std = np.dot(sigmoid_values, WEIGHT)\n",
    "        # 放缩公式: (x - min) / min * 100  (你的代码逻辑)\n",
    "        # 注意: 4.7966 是 min_score (sum(w)*0.5)\n",
    "        dta_standard = ((weighted_sum_std - MIN_SCORE_STD) / MIN_SCORE_STD) * 100\n",
    "\n",
    "        # --- B. 外部真理 (Ground Truth) ---\n",
    "        \n",
    "        # 1. GT Intensity (FASI - 强度)\n",
    "        # 定义为未来真实值的均值 (反映活跃水平)\n",
    "        gt_intensity = true_data.values.mean()\n",
    "        \n",
    "        # 2. GT Slope (你代码中的 FASI，反映增长趋势)\n",
    "        # 保留你的原始逻辑作为参考\n",
    "        total_changes = true_data.iloc[-1] - true_data.iloc[0]\n",
    "        gt_slope = (total_changes / (len(true_data) - 1)).mean()\n",
    "\n",
    "        # 3. GT Stability (1/CV)\n",
    "        # 变异系数倒数. 加上 1e-6 防止除零\n",
    "        means = true_data.mean()\n",
    "        stds = true_data.std()\n",
    "        cvs = stds / (means + 1e-6)\n",
    "        # 取所有特征 CV 的平均值的倒数，或者平均稳定性\n",
    "        # 这里计算平均 CV 然后取倒数\n",
    "        avg_cv = cvs.mean()\n",
    "        gt_stability = 1 / (avg_cv + 1e-6)\n",
    "\n",
    "        total_reviews = true_data.iloc[:, 3].sum()  # ReviewComment 是第4列(索引3)\n",
    "        total_merges = true_data.iloc[:, 4].sum()   # MergePR 是第5列(索引4)\n",
    "        chaoss_review_intensity = total_reviews / (total_merges + 1e-9)  # 添加小值防止除零\n",
    "\n",
    "        # ================= 存储结果 =================\n",
    "        result_dict = {\n",
    "            'Repo_Name': name,\n",
    "            # Ours\n",
    "            'DTA_Standard': dta_standard,\n",
    "            # Ground Truths\n",
    "            'GT_Intensity_Mean': gt_intensity,\n",
    "            'GT_Trend_Slope': gt_slope,\n",
    "            'GT_Stability_InvCV': gt_stability,\n",
    "            'CHAOSS_Review_Intensity': chaoss_review_intensity\n",
    "        }\n",
    "        \n",
    "        results.append(result_dict)\n",
    "        print(f\"{name:<15} | SUCCESS    | DTA: {dta_standard:.2f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{name:<15} | ERROR      | {str(e)}\")\n",
    "\n",
    "# ================= 保存文件 =================\n",
    "if results:\n",
    "    output_dir = 'workresult/stacking/openrank_DTA'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # 按 DTA 分数排序，方便观察\n",
    "    results_df = results_df.sort_values(by='DTA_Standard', ascending=False)\n",
    "    \n",
    "    # 调整列顺序\n",
    "    cols = ['Repo_Name', 'DTA_Standard',\n",
    "            'GT_Intensity_Mean', 'GT_Trend_Slope', 'GT_Stability_InvCV', 'CHAOSS_Review_Intensity']\n",
    "    results_df = results_df[cols]\n",
    "    \n",
    "    save_path = os.path.join(output_dir, 'experiment_master_data.csv')\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"所有数据处理完成！结果已保存至: {save_path}\")\n",
    "    print(f\"成功处理仓库数量: {len(results_df)}\")\n",
    "else:\n",
    "    print(\"\\n未生成任何结果，请检查文件路径配置。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
